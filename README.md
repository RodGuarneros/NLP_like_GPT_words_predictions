# NLP_like_GPT_words_predictions
The basics of Natural Language Model to understand ChatGPT.

ChatGPT  is a language model based on the GPT architecture, which uses a sequence of words prediction approach. It predicts the likelihood of the next word or sequence of words given the preceding context, based on its training on large amounts of text data. This sequence prediction approach allows ChatGPT to generate natural-sounding responses to questions and prompts provided by users. However, it's important to note that ChatGPT's responses are generated based on statistical patterns in the training data, and as a machine learning model, it may not always produce accurate or appropriate responses.

Here you can find a functional example with an application that predicts a sequence of words based on a text. Can you imagine what can you do if you use 44 zettabytes (or 44 trillion gigabytes) of information. This is the last estimation of IDC (International Data Coorporation) as of 2021. This includes everything from websites, social media posts, videos, images, documents, and more. It is important to note that this number is constantly increasing as more and more data is generated and added to the internet every day.

An example of our results: 

![alt text](https://github.com/RodGuarneros/NLP_like_GPT_words_predictions/blob/main/MLEvsMLELAP.png)
